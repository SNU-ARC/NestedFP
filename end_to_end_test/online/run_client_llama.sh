python vllm_simple_client.py --model /home/ubuntu/models/Llama-3.1-8B --api-url http://0.0.0.0:8000/v1/completions --test-mode throughput